### 环境准备 
#### linux
#### 实验目标: 
##### 1. 学习spark-shell的基本使用
##### 2. workCount 联系


## 1. 准备测试文件 workCount.txt
```
w1 w3 w4
w2 w1 w3
w1 w4 w3
w1
w4
w2 w4
```
## 2. spark-shell 测试
```
sc.textFile("file:///opt/test/workCount.txt").flatMap(r => r.split(" ")).map(r => (r, 1)).reduceByKey(_ + _).foreach(println)
sc.textFile("file:///opt/test/workCount.txt").flatMap(r => r.split(" ")).map(r => (r, 1)).reduceByKey((v1, v2) => v1 + v2).foreach(println)
sc.textFile("file:///opt/test/workCount.txt").flatMap(r => r.split(" ")).map(r => (r, 1)).reduceByKey((v1, v2) => v1 + v2).foreach(r => println(r))
```
