#### 一、cloudManager 基本了解， CDH 组件认识
#### 二、Spark 代码编写
####  三、Kafka、Flume 认识


1.  cloudManager 介绍[https://www.cloudera.com](https://www.cloudera.com "")
      [http://apache.org/](http://apache.org/ "")

    1.1 cloudManager 安装(生产环境，离线安装)

         求助搜索引擎: cloudManager 安装过程

         离线安装参考: [https://www.cloudera.com/documentation/enterprise/5-13-x/topics/cm_ig_install_path_c.html](https://www.cloudera.com/documentation/enterprise/5-13-x/topics/cm_ig_install_path_c.html "")


    1.2 cloudManager 单机测试

         docker 快速拉起： [https://www.cloudera.com/documentation/enterprise/5-13-x/topics/quickstart_docker_container.html](https://www.cloudera.com/documentation/enterprise/5-13-x/topics/quickstart_docker_container.html "")
         ```
         docker import cloudera-quickstart-vm-5.13.0-0-beta-docker.tar
         sudo docker images
         sudo docker run --hostname=quickstart.cloudera --privileged=true -t -i -p 7180:7180 -p 8888:8888 -p 8088:8088 -p 50070:50070 -p 11000:11000 -p 20173:22 2527c92864d9 /bin/bash
         /usr/bin/docker-quickstart

         hive, hue(hvieui) 实验（需要联网）
         sqoop，hdfs 看 进度
         ```

    1.3  cloudManager 认识

          启动
          ```
          sudo docker run --hostname=quickstart.cloudera --privileged=true -t -i -p 7180:7180 -p 8888:8888 -p 8088:8088 -p 50070:50070 -p 11000:11000 -p 20173:22 2527c92864d9 /bin/bash
          /usr/bin/docker-quickstart
          /home/cloudera/cloudera-manager --express
          ```
         
          cloudManager 简单了解

          基本组件:

              zookeeper: 分布式协调

              hdfs: 分布式共享存储

              ！！！hive: 数据仓库建设; 访问方式（cli, hue）; 分区; 基本数据结构

              hue: 查询分析、文件访问、任务

              yarn: 资源调度

              oozie: 工作流调度

              ！！！spark: .......

              sqoop, habase, solr
              ............

-------------------------------------------------------------------------------------------------------------------------------------

2. spark(http://spark.apache.org/)

  2.1 spark-shell workCount 查看: 熟悉 spark-shell, spark-ui
   准备测试文件 wordCount.txt
```
w1 w3 w4
w2 w1 w3
w1 w4 w3
w1
w4
w2 w4
```
      spark-shell 测试
```
sc.textFile("file:///opt/test/workCount.txt").flatMap(r => r.split(" ")).map(r => (r, 1)).reduceByKey(_ + _).foreach(println)
sc.textFile("file:///opt/test/workCount.txt").flatMap(r => r.split(" ")).map(r => (r, 1)).reduceByKey((v1, v2) => v1 + v2).foreach(println)
sc.textFile("file:///opt/test/workCount.txt").flatMap(r => r.split(" ")).map(r => (r, 1)).reduceByKey((v1, v2) => v1 + v2).foreach(r => println(r))
```
  
  ！！！！2.2 spark 常用 transformation、action 练习（idea, local)
        1. idea 下载 选择合适版本[https://www.jetbrains.com/idea/download/#section=linux](https://www.jetbrains.com/idea/download/#section=linux "")

        2. window安装, 全部选择默认选项即可

        3. 安装完成， 打开idea

        4. 新建mavne 工程， 添加 idea scala支持; mavne 工程pom.xml  添加如下配置
```
<properties>
        <java.version>1.7</java.version>
    </properties>

    <dependencies>
        <dependency>
            <groupId>org.scala-lang</groupId>
            <artifactId>scala-compiler</artifactId>
            <version>2.10.5</version>
        </dependency>

        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-core_2.10</artifactId>
            <version>1.6.0-cdh5.13.0</version>
        </dependency>
    </dependencies>

    <build>
        <plugins>
            <plugin>
                <groupId>net.alchim31.maven</groupId>
                <artifactId>scala-maven-plugin</artifactId>
                <version>3.2.0</version>
            </plugin>
        </plugins>
    </build>

    <repositories>
        <repository>
            <id>cloudera</id>
            <url>https://repository.cloudera.com/artifactory/cloudera-repos/</url>
        </repository>
        <repository>
            <id>sonatype</id>
            <name>sonatype</name>
            <url>https://oss.sonatype.org/content/groups/public/</url>
            <releases>
                <enabled>true</enabled>
            </releases>
            <snapshots>
                <enabled>true</enabled>
            </snapshots>
        </repository>
    </repositories>

```
              5. 测试 spark 程序， 基本的spark 算子操作

              6.  spark 流处理简单认识
```
import org.apache.spark.SparkConf
import org.apache.spark.streaming.{Seconds, StreamingContext}

object StreamingTest {

  // create streaming : nc -lk 9999
  def main(args: Array[String]): Unit = {

    val conf = new SparkConf().setMaster("local[*]").setAppName("NetworkWordCount")
    val ssc = new StreamingContext(conf, Seconds(1))

    val lines = ssc.socketTextStream("localhost", 9999)
    val words = lines.flatMap(_.split(" "))
    val pairs = words.map(word => (word, 1))
    val wordCounts = pairs.reduceByKey(_ + _)
    wordCounts.print()

    ssc.start()
    ssc.awaitTermination()
  }

}
```              
         7. spark dataframe 测试
```
package test

import org.apache.spark.sql.SQLContext
import org.apache.spark.{SparkConf, SparkContext}

object DFTest {

  case class person(name: String, age: Int)
  def main(args: Array[String]): Unit = {
    val conf = new SparkConf()
    conf.setMaster("local[*]").setAppName("test")
    val sc = new SparkContext(conf)
    val sqlContext = new SQLContext(sc)

    import sqlContext.implicits._

    val array = Array(Array("aif", "21"), Array("aif2", "22"))

    sc.parallelize(array).map(r => person(r(0), r(1).toInt)).toDF().registerTempTable("table1")
    
    sqlContext.sql("select name from table1").show()
  }

}
```         

         2.3 spark 集群上运行
```
// 测试程序打包
// 程序上传集群
// 提交程序, ex:
spark-submit  --master local[*]  --class test.WordCount BigDataLearn-1.0-SNAPSHOT.jar file:///home/cloudera/cm_api.py
```
         2.4 spark 远程调试
 ```
 spark-submit  --master local[2] --conf spark.dynamicAllocation.enabled=false --driver-java-options "-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=5555" --conf spark.ui.port=4040 --class test.WordCount BigDataLearn-1.0-SNAPSHOT.jar file:///home/cloudera/cm_api.py
 ```
-------------------------------------------------------------------------------------------------------------------------------------
3 . 大数据其他常用
        
        3.1 kafka，kafka 单机搭建， topic, partition 认识

        3.2 flume 了解， 常用于日志收集 https://flume.apache.org/， 
         windows 测试参考： https://blog.csdn.net/u012107143/article/details/72638628?utm_source=itdadao&utm_medium=referral

        3.3 ........

-------------------------------------------------------------------------------------------------------------------------------------

4. 关系数据库分区分表

