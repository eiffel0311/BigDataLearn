1.  cloudManager 介绍[https://www.cloudera.com](https://www.cloudera.com "")
      [http://apache.org/](http://apache.org/ "")

    1.1 cloudManager 安装(生产环境，离线安装)

         求助搜索引擎: cloudManager 安装过程

         离线安装参考: [https://www.cloudera.com/documentation/enterprise/5-13-x/topics/cm_ig_install_path_c.html](https://www.cloudera.com/documentation/enterprise/5-13-x/topics/cm_ig_install_path_c.html "")


    1.2 cloudManager 单机测试

         docker 快速拉起： [https://www.cloudera.com/documentation/enterprise/5-13-x/topics/quickstart_docker_container.html](https://www.cloudera.com/documentation/enterprise/5-13-x/topics/quickstart_docker_container.html "")
         ```
         docker import cloudera-quickstart-vm-5.13.0-0-beta-docker.tar
         sudo docker images
         sudo docker run --hostname=quickstart.cloudera --privileged=true -t -i -p 7180:7180 -p 8888:8888 -p 8088:8088 -p 50070:50070 -p 11000:11000 -p 20173:22 2527c92864d9 /bin/bash
         /usr/bin/docker-quickstart
         ```

    1.3  cloudManager 认识

          启动
          ```
          sudo docker run --hostname=quickstart.cloudera --privileged=true -t -i -p 7180:7180 -p 8888:8888 -p 8088:8088 -p 50070:50070 -p 11000:11000 -p 20173:22 2527c92864d9 /bin/bash
          /usr/bin/docker-quickstart
          /home/cloudera/cloudera-manager --express
          ```
         
          cloudManager 简单了解

          基本组件:

              zookeeper: 分布式协调

              hdfs: 分布式共享存储

              ！！！hive: 数据仓库建设; 访问方式（cli, hue）; 分区; 基本数据结构

              hue: 查询分析、文件访问、任务

              yarn: 资源调度

              oozie: 工作流调度

              ！！！spark: .......

              sqoop, habase, solr
              ............

-------------------------------------------------------------------------------------------------------------------------------------

2. spark(http://spark.apache.org/)

  2.1 spark-shell workCount 查看: 熟悉 spark-shell, spark-ui
   准备测试文件 wordCount.txt
```
w1 w3 w4
w2 w1 w3
w1 w4 w3
w1
w4
w2 w4
```
      spark-shell 测试
```
sc.textFile("file:///opt/test/workCount.txt").flatMap(r => r.split(" ")).map(r => (r, 1)).reduceByKey(_ + _).foreach(println)
sc.textFile("file:///opt/test/workCount.txt").flatMap(r => r.split(" ")).map(r => (r, 1)).reduceByKey((v1, v2) => v1 + v2).foreach(println)
sc.textFile("file:///opt/test/workCount.txt").flatMap(r => r.split(" ")).map(r => (r, 1)).reduceByKey((v1, v2) => v1 + v2).foreach(r => println(r))
```
  
  ！！！！2.2 spark 常用 transformation、action 练习（idea, local)
        1. idea 下载 选择合适版本[https://www.jetbrains.com/idea/download/#section=linux](https://www.jetbrains.com/idea/download/#section=linux "")

        2. window安装, 全部选择默认选项即可

        3. 安装完成， 打开idea

        4. 新建mavne 工程， 添加 idea scala支持; mavne 工程pom.xml  添加如下配置
```
<properties>
        <java.version>1.7</java.version>
    </properties>

    <dependencies>
        <dependency>
            <groupId>org.scala-lang</groupId>
            <artifactId>scala-compiler</artifactId>
            <version>2.10.5</version>
        </dependency>

        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-core_2.10</artifactId>
            <version>1.6.0-cdh5.13.0</version>
        </dependency>
    </dependencies>

    <build>
        <plugins>
            <plugin>
                <groupId>net.alchim31.maven</groupId>
                <artifactId>scala-maven-plugin</artifactId>
                <version>3.2.0</version>
            </plugin>
        </plugins>
    </build>

    <repositories>
        <repository>
            <id>cloudera</id>
            <url>https://repository.cloudera.com/artifactory/cloudera-repos/</url>
        </repository>
        <repository>
            <id>sonatype</id>
            <name>sonatype</name>
            <url>https://oss.sonatype.org/content/groups/public/</url>
            <releases>
                <enabled>true</enabled>
            </releases>
            <snapshots>
                <enabled>true</enabled>
            </snapshots>
        </repository>
    </repositories>

```
              5. 测试 spark 程序

         2.3 spark 集群上运行
```
// 测试程序打包
// 程序上传集群
// 提交程序, ex:
spark-submit  --master local[*]  --class test.WordCount BigDataLearn-1.0-SNAPSHOT.jar file:///home/cloudera/cm_api.py
```
         2.4 spark 远程调试
 ```
 spark-submit  --master local[2] --conf spark.dynamicAllocation.enabled=false --driver-java-options "-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=5555" --conf spark.ui.port=4040 --class test.WordCount BigDataLearn-1.0-SNAPSHOT.jar file:///home/cloudera/cm_api.py
 ```
-------------------------------------------------------------------------------------------------------------------------------------
3 . 大数据其他常用
        
        3.1 kafka，kafka 单机搭建， topic, partition 认识

        3.2 flume 了解， 常用于日志收集

        3.3 ........

-------------------------------------------------------------------------------------------------------------------------------------










2. kafka

  2.1 kafka产生背景、使用场景
  
  2.2 kafka 特点
  
  2.3 kafka 设计
  
       文件分段
       partition
       message
       文件索引，index
        
  2.4 传统消息队列对比
  
  2.5 kafka 架构
  
  2.6 kafka 基本概念
  
       topic
       partition
         高并发
         数据量
       broker
         大力节点， 可批量写入
         无状态
       producer
         起步批量处理， 提高效率
       consumer
          consumer group
       message
          offset
          massageSize
          data
          处理机制：根据index 搜索 log 文件
         发送机制
         
  2.7 kafka事务
  
      at-least-once
      at-most-once
      exactly-once

  2.8 kafka 存储策略
  
      topic -> partition -> segment

  2.9 Kafka的分布式实现

  实验4 kafka安装使用


3. flume

  3.1 简介
  
  3.2 架构
  
      source, sink, channle, interceptor, 可靠性
      
  3.3 使用场景

   实验5: flume 安装测试


4. spark

    4.1 简介
    
    4.2 特点
    
       快速， 通用，高度开放
       
    4.3 组件
    
        spark sql , ml, streaming, graphx

    4.4 核心概念
    
        driver(sparkContext), executor, rdd, 函数（序列化问题）

    4.5 RDD介绍
    
        rdd 概念
        rdd 血缘关系

    4.6 trandformations
    
        map
        结合操作
        常见tf

    4.7 action


    实验6: spark wordCount

5. 整个串联